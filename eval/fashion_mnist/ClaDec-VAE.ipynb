{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "\n",
    "file_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "home_dir = pathlib.Path(file_path).parent.parent.parent\n",
    "os.chdir(home_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 14:32:44.627667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 14:32:44.675856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 14:32:44.676097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 14:32:44.677013: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-09 14:32:44.698645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 14:32:44.699081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 14:32:44.699432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 14:32:45.238248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 14:32:45.238476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 14:32:45.238640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-09 14:32:45.238766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3361 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from src.utils import get_optimizer, SAVED_CLASSIFIER_PATH_FASHION, keras_dataset_image_preprocessing, DENSE_LAYER_NAME\n",
    "\n",
    "from src.vae import ClaDecVAE\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "(train_images, train_labels_c), (test_images, test_labels_c) = keras_dataset_image_preprocessing(\n",
    "    keras.datasets.fashion_mnist)\n",
    "# get the trained model and check accuracy on test data for later reference\n",
    "classifier = keras.models.load_model(SAVED_CLASSIFIER_PATH_FASHION)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 14:32:47.236010: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 4ms/step - loss: 0.2533 - categorical_accuracy: 0.9101\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " my_conv (MaxPooling2D)      (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3136)              0         \n",
      "                                                                 \n",
      " my_dense (Dense)            (None, 128)               401536    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 422,026\n",
      "Trainable params: 421,834\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.evaluate(test_images, test_labels_c)\n",
    "classifier.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class ClaDecVAE with abstract method test_step",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m latent_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m      3\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m get_optimizer()\n\u001B[0;32m----> 4\u001B[0m claDec \u001B[38;5;241m=\u001B[39m \u001B[43mClaDecVAE\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclassifier\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDENSE_LAYER_NAME\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlatent_dim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m claDec\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mget_optimizer())\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/cladec-mnist-KzwMDeQR/lib/python3.10/site-packages/keras/engine/training.py:184\u001B[0m, in \u001B[0;36mModel.__new__\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    182\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m functional\u001B[38;5;241m.\u001B[39mFunctional(skip_init\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 184\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mModel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__new__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/cladec-mnist-KzwMDeQR/lib/python3.10/site-packages/keras/utils/version_utils.py:62\u001B[0m, in \u001B[0;36mLayerVersionSelector.__new__\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     60\u001B[0m use_v2 \u001B[38;5;241m=\u001B[39m should_use_v2()\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m swap_class(\u001B[38;5;28mcls\u001B[39m, base_layer\u001B[38;5;241m.\u001B[39mLayer, base_layer_v1\u001B[38;5;241m.\u001B[39mLayer, use_v2)  \u001B[38;5;66;03m# pylint: disable=self-cls-assignment\u001B[39;00m\n\u001B[0;32m---> 62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mLayerVersionSelector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__new__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/cladec-mnist-KzwMDeQR/lib/python3.10/site-packages/keras/utils/version_utils.py:53\u001B[0m, in \u001B[0;36mModelVersionSelector.__new__\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     51\u001B[0m use_v2 \u001B[38;5;241m=\u001B[39m should_use_v2()\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m swap_class(\u001B[38;5;28mcls\u001B[39m, training\u001B[38;5;241m.\u001B[39mModel, training_v1\u001B[38;5;241m.\u001B[39mModel, use_v2)  \u001B[38;5;66;03m# pylint: disable=self-cls-assignment\u001B[39;00m\n\u001B[0;32m---> 53\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mModelVersionSelector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__new__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: Can't instantiate abstract class ClaDecVAE with abstract method test_step"
     ]
    }
   ],
   "source": [
    "alpha = 0.9\n",
    "latent_dim = 2\n",
    "optimizer = get_optimizer()\n",
    "claDec = ClaDecVAE(classifier, DENSE_LAYER_NAME, alpha, latent_dim)\n",
    "claDec.compile(optimizer=get_optimizer())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "claDec.fit(train_images, train_labels_c, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier.evaluate(test_images, test_labels_c)  # classifier weights not altered"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_latent_space(vae, n=30, figsize=30):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 28\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = vae.decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "            i * digit_size: (i + 1) * digit_size,\n",
    "            j * digit_size: (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_space(claDec)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_label_clusters(vae, data, classes):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    acts = vae.model_up_to_layer_to_explain(data)\n",
    "    z_mean, _, _ = vae.encoder.predict(acts)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=classes)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "test_labels = np.argmax(test_labels_c, axis=1)\n",
    "train_labels = np.argmax(train_labels_c, axis=1)\n",
    "encoding = [\"T-Shirt (Top)\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
    "plot_label_clusters(claDec, train_images[:10000], train_labels[:10000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_label_clusters(claDec, test_images, test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}