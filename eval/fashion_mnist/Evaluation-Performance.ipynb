{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26271def-641f-48f5-87b2-88c53cf1e4a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "\n",
    "file_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "home_dir = pathlib.Path(file_path).parent.parent\n",
    "os.chdir(home_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f995e98-7021-4614-99c1-217d0752a3ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Unnamed: 0        dataset     layer                 eval  classifier  \\\n0            0  fashion_mnist  my_dense           total_loss    0.228498   \n1            1  fashion_mnist  my_dense  reconstruction_loss         NaN   \n2            2  fashion_mnist  my_dense  classification_loss    0.228498   \n3            3  fashion_mnist  my_dense  evaluation_accuracy    0.920600   \n4            4  fashion_mnist   my_conv           total_loss    0.228498   \n5            5  fashion_mnist   my_conv  reconstruction_loss         NaN   \n6            6  fashion_mnist   my_conv  classification_loss    0.228498   \n7            7  fashion_mnist   my_conv  evaluation_accuracy    0.920600   \n8            8          mnist  my_dense           total_loss    0.037522   \n9            9          mnist  my_dense  reconstruction_loss         NaN   \n10          10          mnist  my_dense  classification_loss    0.037522   \n11          11          mnist  my_dense  evaluation_accuracy    0.990300   \n12          12          mnist   my_conv           total_loss    0.037522   \n13          13          mnist   my_conv  reconstruction_loss         NaN   \n14          14          mnist   my_conv  classification_loss    0.037522   \n15          15          mnist   my_conv  evaluation_accuracy    0.990300   \n\n       refAE          0          1          5         10         25  \\\n0   7.124279  21.836708  21.761026  20.813839  19.769808  16.493725   \n1   7.124279  21.836708  21.972736  21.874737  21.904966  21.857809   \n2        NaN   0.875324   0.802315   0.656808   0.553377   0.401475   \n3   0.888700   0.903300   0.904600   0.905400   0.905600   0.907600   \n4   1.125318   3.543053   3.508368   3.383557   3.239841   2.740736   \n5   1.125318   3.543053   3.540704   3.545505   3.566517   3.560159   \n6        NaN   0.308961   0.307043   0.306536   0.299761   0.282462   \n7   0.908000   0.904500   0.892100   0.904600   0.905800   0.908000   \n8   3.131160  20.522276  20.367018  19.583939  18.485197  15.485126   \n9   3.131160  20.522276  20.571531  20.608286  20.526329  20.612139   \n10       NaN   0.128489   0.119467   0.121317   0.115034   0.104087   \n11  0.987100   0.984000   0.983900   0.985000   0.985500   0.984600   \n12  0.359455   1.467101   1.473641   1.405788   1.311100   1.107619   \n13  0.359455   1.467101   1.488056   1.477415   1.451660   1.461840   \n14       NaN   0.045355   0.046603   0.044882   0.046059   0.044959   \n15  0.991400   0.989300   0.989300   0.990400   0.990800   0.989100   \n\n           50         99       99.9       99.99         100  \n0   11.121116   0.631990   0.431054    0.365682    0.347074  \n1   21.926941  30.009632  90.457542  275.725006  375.310516  \n2    0.315300   0.335246   0.340938    0.338143    0.347074  \n3    0.907800   0.913900   0.914000    0.912600    0.912900  \n4    1.926461   0.335954   0.295887    0.368075    0.332982  \n5    3.585461   8.962866  26.455465  100.750717   93.023277  \n6    0.267461   0.248813   0.269701    0.358036    0.332982  \n7    0.908400   0.908400   0.909900    0.910800    0.906400  \n8   10.302245   0.294454   0.171916    0.148933    0.129434  \n9   20.515209  24.082470  87.526779  304.325165  312.463287  \n10   0.089289   0.054171   0.084474    0.118512    0.129434  \n11   0.985100   0.986100   0.987100    0.987100    0.986700  \n12   0.752191   0.067424   0.122476    0.110035    0.127953  \n13   1.459659   2.784479  32.315445   55.991257  153.482407  \n14   0.044723   0.039979   0.090251    0.104446    0.127953  \n15   0.989900   0.989800   0.986500    0.985700    0.984500  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>dataset</th>\n      <th>layer</th>\n      <th>eval</th>\n      <th>classifier</th>\n      <th>refAE</th>\n      <th>0</th>\n      <th>1</th>\n      <th>5</th>\n      <th>10</th>\n      <th>25</th>\n      <th>50</th>\n      <th>99</th>\n      <th>99.9</th>\n      <th>99.99</th>\n      <th>100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>fashion_mnist</td>\n      <td>my_dense</td>\n      <td>total_loss</td>\n      <td>0.228498</td>\n      <td>7.124279</td>\n      <td>21.836708</td>\n      <td>21.761026</td>\n      <td>20.813839</td>\n      <td>19.769808</td>\n      <td>16.493725</td>\n      <td>11.121116</td>\n      <td>0.631990</td>\n      <td>0.431054</td>\n      <td>0.365682</td>\n      <td>0.347074</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>fashion_mnist</td>\n      <td>my_dense</td>\n      <td>reconstruction_loss</td>\n      <td>NaN</td>\n      <td>7.124279</td>\n      <td>21.836708</td>\n      <td>21.972736</td>\n      <td>21.874737</td>\n      <td>21.904966</td>\n      <td>21.857809</td>\n      <td>21.926941</td>\n      <td>30.009632</td>\n      <td>90.457542</td>\n      <td>275.725006</td>\n      <td>375.310516</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>fashion_mnist</td>\n      <td>my_dense</td>\n      <td>classification_loss</td>\n      <td>0.228498</td>\n      <td>NaN</td>\n      <td>0.875324</td>\n      <td>0.802315</td>\n      <td>0.656808</td>\n      <td>0.553377</td>\n      <td>0.401475</td>\n      <td>0.315300</td>\n      <td>0.335246</td>\n      <td>0.340938</td>\n      <td>0.338143</td>\n      <td>0.347074</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>fashion_mnist</td>\n      <td>my_dense</td>\n      <td>evaluation_accuracy</td>\n      <td>0.920600</td>\n      <td>0.888700</td>\n      <td>0.903300</td>\n      <td>0.904600</td>\n      <td>0.905400</td>\n      <td>0.905600</td>\n      <td>0.907600</td>\n      <td>0.907800</td>\n      <td>0.913900</td>\n      <td>0.914000</td>\n      <td>0.912600</td>\n      <td>0.912900</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>fashion_mnist</td>\n      <td>my_conv</td>\n      <td>total_loss</td>\n      <td>0.228498</td>\n      <td>1.125318</td>\n      <td>3.543053</td>\n      <td>3.508368</td>\n      <td>3.383557</td>\n      <td>3.239841</td>\n      <td>2.740736</td>\n      <td>1.926461</td>\n      <td>0.335954</td>\n      <td>0.295887</td>\n      <td>0.368075</td>\n      <td>0.332982</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>fashion_mnist</td>\n      <td>my_conv</td>\n      <td>reconstruction_loss</td>\n      <td>NaN</td>\n      <td>1.125318</td>\n      <td>3.543053</td>\n      <td>3.540704</td>\n      <td>3.545505</td>\n      <td>3.566517</td>\n      <td>3.560159</td>\n      <td>3.585461</td>\n      <td>8.962866</td>\n      <td>26.455465</td>\n      <td>100.750717</td>\n      <td>93.023277</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>fashion_mnist</td>\n      <td>my_conv</td>\n      <td>classification_loss</td>\n      <td>0.228498</td>\n      <td>NaN</td>\n      <td>0.308961</td>\n      <td>0.307043</td>\n      <td>0.306536</td>\n      <td>0.299761</td>\n      <td>0.282462</td>\n      <td>0.267461</td>\n      <td>0.248813</td>\n      <td>0.269701</td>\n      <td>0.358036</td>\n      <td>0.332982</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>fashion_mnist</td>\n      <td>my_conv</td>\n      <td>evaluation_accuracy</td>\n      <td>0.920600</td>\n      <td>0.908000</td>\n      <td>0.904500</td>\n      <td>0.892100</td>\n      <td>0.904600</td>\n      <td>0.905800</td>\n      <td>0.908000</td>\n      <td>0.908400</td>\n      <td>0.908400</td>\n      <td>0.909900</td>\n      <td>0.910800</td>\n      <td>0.906400</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>mnist</td>\n      <td>my_dense</td>\n      <td>total_loss</td>\n      <td>0.037522</td>\n      <td>3.131160</td>\n      <td>20.522276</td>\n      <td>20.367018</td>\n      <td>19.583939</td>\n      <td>18.485197</td>\n      <td>15.485126</td>\n      <td>10.302245</td>\n      <td>0.294454</td>\n      <td>0.171916</td>\n      <td>0.148933</td>\n      <td>0.129434</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>mnist</td>\n      <td>my_dense</td>\n      <td>reconstruction_loss</td>\n      <td>NaN</td>\n      <td>3.131160</td>\n      <td>20.522276</td>\n      <td>20.571531</td>\n      <td>20.608286</td>\n      <td>20.526329</td>\n      <td>20.612139</td>\n      <td>20.515209</td>\n      <td>24.082470</td>\n      <td>87.526779</td>\n      <td>304.325165</td>\n      <td>312.463287</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>mnist</td>\n      <td>my_dense</td>\n      <td>classification_loss</td>\n      <td>0.037522</td>\n      <td>NaN</td>\n      <td>0.128489</td>\n      <td>0.119467</td>\n      <td>0.121317</td>\n      <td>0.115034</td>\n      <td>0.104087</td>\n      <td>0.089289</td>\n      <td>0.054171</td>\n      <td>0.084474</td>\n      <td>0.118512</td>\n      <td>0.129434</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>mnist</td>\n      <td>my_dense</td>\n      <td>evaluation_accuracy</td>\n      <td>0.990300</td>\n      <td>0.987100</td>\n      <td>0.984000</td>\n      <td>0.983900</td>\n      <td>0.985000</td>\n      <td>0.985500</td>\n      <td>0.984600</td>\n      <td>0.985100</td>\n      <td>0.986100</td>\n      <td>0.987100</td>\n      <td>0.987100</td>\n      <td>0.986700</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>mnist</td>\n      <td>my_conv</td>\n      <td>total_loss</td>\n      <td>0.037522</td>\n      <td>0.359455</td>\n      <td>1.467101</td>\n      <td>1.473641</td>\n      <td>1.405788</td>\n      <td>1.311100</td>\n      <td>1.107619</td>\n      <td>0.752191</td>\n      <td>0.067424</td>\n      <td>0.122476</td>\n      <td>0.110035</td>\n      <td>0.127953</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>mnist</td>\n      <td>my_conv</td>\n      <td>reconstruction_loss</td>\n      <td>NaN</td>\n      <td>0.359455</td>\n      <td>1.467101</td>\n      <td>1.488056</td>\n      <td>1.477415</td>\n      <td>1.451660</td>\n      <td>1.461840</td>\n      <td>1.459659</td>\n      <td>2.784479</td>\n      <td>32.315445</td>\n      <td>55.991257</td>\n      <td>153.482407</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>mnist</td>\n      <td>my_conv</td>\n      <td>classification_loss</td>\n      <td>0.037522</td>\n      <td>NaN</td>\n      <td>0.045355</td>\n      <td>0.046603</td>\n      <td>0.044882</td>\n      <td>0.046059</td>\n      <td>0.044959</td>\n      <td>0.044723</td>\n      <td>0.039979</td>\n      <td>0.090251</td>\n      <td>0.104446</td>\n      <td>0.127953</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>mnist</td>\n      <td>my_conv</td>\n      <td>evaluation_accuracy</td>\n      <td>0.990300</td>\n      <td>0.991400</td>\n      <td>0.989300</td>\n      <td>0.989300</td>\n      <td>0.990400</td>\n      <td>0.990800</td>\n      <td>0.989100</td>\n      <td>0.989900</td>\n      <td>0.989800</td>\n      <td>0.986500</td>\n      <td>0.985700</td>\n      <td>0.984500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.utils import SAVED_EVAL_BASE_PATH\n",
    "\n",
    "df = pd.read_csv(SAVED_EVAL_BASE_PATH.joinpath(\"evaluation_result.csv\"))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cladec-mnist",
   "language": "python",
   "name": "cladec-mnist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}